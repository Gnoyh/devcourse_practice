{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIA23YgbXKJd"
      },
      "source": [
        "이를 위해 pyspark과 Py4J 패키지를 설치한다. Py4J 패키지는 파이썬 프로그램이 자바가상머신상의 오브젝트들을 접근할 수 있게 해준다. Local Standalone Spark을 사용한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbT0rpGfVdiq",
        "outputId": "0e510cc0-aa5e-4bfe-bf36-7c8d44beaa4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyspark==3.3.1\n",
            "  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845493 sha256=e750b1ebc07617ee7116f668ac626c816dbbe386ad7f473824a1e05975e37db1\n",
            "  Stored in directory: /root/.cache/pip/wheels/0f/f0/3d/517368b8ce80486e84f89f214e0a022554e4ee64969f46279b\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "  Attempting uninstall: py4j\n",
            "    Found existing installation: py4j 0.10.9.7\n",
            "    Uninstalling py4j-0.10.9.7:\n",
            "      Successfully uninstalled py4j-0.10.9.7\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark==3.3.1 py4j==0.10.9.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfwRP7poGOtw",
        "outputId": "65c8ab18-f694-467e-beb8-9c2fca0732d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-06-20 05:22:49--  https://s3.amazonaws.com/redshift-downloads/drivers/jdbc/2.1.0.28/redshift-jdbc42-2.1.0.28.jar\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 54.231.236.128, 54.231.232.152, 52.217.116.32, ...\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|54.231.236.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1077030 (1.0M) [application/java-archive]\n",
            "Saving to: ‘redshift-jdbc42-2.1.0.28.jar’\n",
            "\n",
            "redshift-jdbc42-2.1 100%[===================>]   1.03M  2.33MB/s    in 0.4s    \n",
            "\n",
            "2024-06-20 05:22:50 (2.33 MB/s) - ‘redshift-jdbc42-2.1.0.28.jar’ saved [1077030/1077030]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!cd /usr/local/lib/python3.10/dist-packages/pyspark/jars && wget https://s3.amazonaws.com/redshift-downloads/drivers/jdbc/2.1.0.28/redshift-jdbc42-2.1.0.28.jar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ew_eTGrvXlDw"
      },
      "source": [
        "**Spark Session**을 하나 만든다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3vm6tgcPXdnR"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Python Spark SQL 저장하기\") \\\n",
        "    .config(\"spark.sql.autoBroadcastJoinThreshold\", -1) \\\n",
        "    .config(\"spark.sql.adaptive.enabled\", False) \\\n",
        "    .enableHiveSupport() \\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUjtIUGWGXVQ"
      },
      "source": [
        "Redshift와 연결해서 DataFrame으로 로딩하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UKrMnuGVK77P"
      },
      "outputs": [],
      "source": [
        "url = \"jdbc:redshift://learnde.cduaw970ssvt.ap-northeast-2.redshift.amazonaws.com:5439/dev?user=guest&password=****\"\n",
        "\n",
        "df_user_session_channel = spark.read \\\n",
        "    .format(\"jdbc\") \\\n",
        "    .option(\"driver\", \"com.amazon.redshift.jdbc42.Driver\") \\\n",
        "    .option(\"url\", url) \\\n",
        "    .option(\"dbtable\", \"raw_data.user_session_channel\") \\\n",
        "    .load()\n",
        "\n",
        "df_session_timestamp = spark.read \\\n",
        "    .format(\"jdbc\") \\\n",
        "    .option(\"driver\", \"com.amazon.redshift.jdbc42.Driver\") \\\n",
        "    .option(\"url\", url) \\\n",
        "    .option(\"dbtable\", \"raw_data.session_timestamp\") \\\n",
        "    .load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6CMLfTGzGk16"
      },
      "outputs": [],
      "source": [
        "join_expr = df_user_session_channel.sessionid == df_session_timestamp.sessionid\n",
        "df_join = df_user_session_channel.join(df_session_timestamp, join_expr, \"inner\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8X_9i4hbGnA6",
        "outputId": "7da4dd3f-2213-465f-d5aa-088fc13e4212"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+--------------------+--------+--------------------+--------------------+\n",
            "|userid|           sessionid| channel|           sessionid|                  ts|\n",
            "+------+--------------------+--------+--------------------+--------------------+\n",
            "|  1501|0135456d6a3c1051f...|  Google|0135456d6a3c1051f...|2019-09-24 14:49:...|\n",
            "|   876|01a416a7e28d0d229...|Facebook|01a416a7e28d0d229...|2019-05-26 14:23:...|\n",
            "|   243|0226aa5193c66d990...|  Google|0226aa5193c66d990...|2019-07-01 23:04:...|\n",
            "|  2776|029bf49b584c641f0...|Facebook|029bf49b584c641f0...|2019-11-11 20:37:...|\n",
            "|   939|02b8d6c2775b756de...|  Google|02b8d6c2775b756de...|2019-09-01 15:29:...|\n",
            "|  2133|02ea66ee24d57e285...| Organic|02ea66ee24d57e285...| 2019-10-28 22:50:40|\n",
            "|   771|02f6364bf207d6837...|   Naver|02f6364bf207d6837...|2019-09-07 18:24:...|\n",
            "|  1961|0302915889fa38fe5...| Youtube|0302915889fa38fe5...| 2019-11-29 15:16:49|\n",
            "|  2139|039cc47f960921e3c...|   Naver|039cc47f960921e3c...| 2019-08-01 18:19:34|\n",
            "|   599|03ce0331cbd983f16...| Organic|03ce0331cbd983f16...|2019-07-18 13:49:...|\n",
            "+------+--------------------+--------+--------------------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_join.show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUanK7rzGoal",
        "outputId": "b6e6f0bb-7c77-4a0b-bfd3-aa683aef2a94"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spark.sql(\"DROP TABLE IF EXISTS bk_usc\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtbNIWalGsaA",
        "outputId": "6079efab-a48f-4fe7-ae4f-a620413abeda"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spark.sql(\"DROP TABLE IF EXISTS bk_st\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "HraLI47SGxEU"
      },
      "outputs": [],
      "source": [
        "df_user_session_channel.write.mode(\"overwrite\").bucketBy(3, \"sessionid\").saveAsTable(\"bk_usc\")\n",
        "df_session_timestamp.write.mode(\"overwrite\").bucketBy(3, \"sessionid\").saveAsTable(\"bk_st\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "kzIIBGBJG0eN"
      },
      "outputs": [],
      "source": [
        "df_bk_usc = spark.read.table(\"bk_usc\")\n",
        "df_bk_st = spark.read.table(\"bk_st\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "hs8AzsgqHBdc"
      },
      "outputs": [],
      "source": [
        "join_expr2 = df_bk_usc.sessionid == df_bk_st.sessionid\n",
        "df_join2 = df_bk_usc.join(df_bk_st, join_expr2, \"inner\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91I6Xx-NHDkB",
        "outputId": "d2d81274-fca7-4b69-c811-2bbc25a106d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+--------------------+---------+--------------------+--------------------+\n",
            "|userid|           sessionid|  channel|           sessionid|                  ts|\n",
            "+------+--------------------+---------+--------------------+--------------------+\n",
            "|  1491|00029153d12ae1c9a...|  Organic|00029153d12ae1c9a...|2019-10-18 14:14:...|\n",
            "|  1667|000958fdaefe0dd06...|Instagram|000958fdaefe0dd06...|2019-11-02 14:52:...|\n",
            "|   468|000a3f777828d2cdb...| Facebook|000a3f777828d2cdb...| 2019-11-29 16:33:55|\n",
            "|   780|000c076c390a4c357...|    Naver|000c076c390a4c357...|2019-05-02 15:24:...|\n",
            "|   711|00106ac9184e7d54b...|  Organic|00106ac9184e7d54b...|2019-07-25 18:14:...|\n",
            "|  1653|0012a83c1e6cda9d7...|   Google|0012a83c1e6cda9d7...| 2019-08-07 16:08:41|\n",
            "|    64|001a3678cacf4ea11...|Instagram|001a3678cacf4ea11...|2019-10-04 19:57:...|\n",
            "|  2027|001c4bab90e1fbf3a...| Facebook|001c4bab90e1fbf3a...| 2019-11-20 20:23:10|\n",
            "|   197|001d3439223b7bb23...|    Naver|001d3439223b7bb23...|2019-08-14 15:14:...|\n",
            "|  1513|001f35b87b35111bc...|  Organic|001f35b87b35111bc...|2019-08-05 01:17:...|\n",
            "+------+--------------------+---------+--------------------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_join2.show(10)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
