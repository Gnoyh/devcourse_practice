{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Efh-3P4StVBg"
      },
      "source": [
        "## PySpark 설치"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbT0rpGfVdiq",
        "outputId": "c3f626cd-f5ed-452a-ee07-bab82bacedf4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyspark==3.3.1\n",
            "  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845493 sha256=e4aa83133aeecf086b4217b4d660ac493e7da07c65b7cd5c5f89c98da571effc\n",
            "  Stored in directory: /root/.cache/pip/wheels/0f/f0/3d/517368b8ce80486e84f89f214e0a022554e4ee64969f46279b\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "  Attempting uninstall: py4j\n",
            "    Found existing installation: py4j 0.10.9.7\n",
            "    Uninstalling py4j-0.10.9.7:\n",
            "      Successfully uninstalled py4j-0.10.9.7\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark==3.3.1 py4j==0.10.9.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdTTZZqVA0Xa",
        "outputId": "9d0ec6b9-52b7-4075-f50e-ff995bd6ef3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-06-19 05:20:16--  https://s3.amazonaws.com/redshift-downloads/drivers/jdbc/2.1.0.28/redshift-jdbc42-2.1.0.28.jar\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.229.216, 52.216.44.144, 52.217.137.24, ...\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.229.216|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1077030 (1.0M) [application/java-archive]\n",
            "Saving to: ‘redshift-jdbc42-2.1.0.28.jar’\n",
            "\n",
            "redshift-jdbc42-2.1 100%[===================>]   1.03M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-06-19 05:20:16 (8.27 MB/s) - ‘redshift-jdbc42-2.1.0.28.jar’ saved [1077030/1077030]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!cd /usr/local/lib/python3.10/dist-packages/pyspark/jars && wget https://s3.amazonaws.com/redshift-downloads/drivers/jdbc/2.1.0.28/redshift-jdbc42-2.1.0.28.jar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3vm6tgcPXdnR"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Python Spark SQL #1\") \\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElawwmWzcylW"
      },
      "source": [
        "## Redshift 상의 다음 테이블을 이용하여 월별 채널별 매출과 방문자 정보 계산하기\n",
        "user_session_channel, session_timestamp, session_transaction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "EEaNuN3xKNXm"
      },
      "outputs": [],
      "source": [
        "# Redshift와 연결해서 DataFrame으로 로딩하기\n",
        "url = \"jdbc:redshift://learnde.cduaw970ssvt.ap-northeast-2.redshift.amazonaws.com:5439/dev?user=guest&password=****\"\n",
        "\n",
        "df_user_session_channel = spark.read \\\n",
        "    .format(\"jdbc\") \\\n",
        "    .option(\"driver\", \"com.amazon.redshift.jdbc42.Driver\") \\\n",
        "    .option(\"url\", url) \\\n",
        "    .option(\"dbtable\", \"raw_data.user_session_channel\") \\\n",
        "    .load()\n",
        "\n",
        "df_session_timestamp = spark.read \\\n",
        "    .format(\"jdbc\") \\\n",
        "    .option(\"driver\", \"com.amazon.redshift.jdbc42.Driver\") \\\n",
        "    .option(\"url\", url) \\\n",
        "    .option(\"dbtable\", \"raw_data.session_timestamp\") \\\n",
        "    .load()\n",
        "\n",
        "df_session_transaction = spark.read \\\n",
        "    .format(\"jdbc\") \\\n",
        "    .option(\"driver\", \"com.amazon.redshift.jdbc42.Driver\") \\\n",
        "    .option(\"url\", url) \\\n",
        "    .option(\"dbtable\", \"raw_data.session_transaction\") \\\n",
        "    .load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "AjcT5LWi7_B5"
      },
      "outputs": [],
      "source": [
        "df_user_session_channel.createOrReplaceTempView(\"user_session_channel\")\n",
        "df_session_timestamp.createOrReplaceTempView(\"session_timestamp\")\n",
        "df_session_transaction.createOrReplaceTempView(\"session_transaction\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3UxHdoLC5Bt",
        "outputId": "483ff43d-1b8b-4d28-cd6c-4b35952ad92b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+--------------------+-------+\n",
            "|userid|           sessionid|channel|\n",
            "+------+--------------------+-------+\n",
            "|  1491|00029153d12ae1c9a...|Organic|\n",
            "|    59|0002ac0d783338cfe...|  Naver|\n",
            "|   117|0006246bee639c7a7...|Youtube|\n",
            "|   572|0006dd05ea1e999dd...|Organic|\n",
            "|   935|0007cda84fafdcf42...| Google|\n",
            "+------+--------------------+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_user_session_channel.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9lIcukADIgk",
        "outputId": "238b0512-2660-46c0-9ae9-29cf40520c6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+\n",
            "|           sessionid|                  ts|\n",
            "+--------------------+--------------------+\n",
            "|0002ac0d783338cfe...|2019-07-29 12:39:...|\n",
            "|00053f5e11d1fe4e4...|2019-06-24 13:04:...|\n",
            "|00056c20eb5a02958...| 2019-09-26 14:50:17|\n",
            "|00063cb5da1826feb...|2019-10-16 14:04:...|\n",
            "|0007cda84fafdcf42...|2019-05-22 08:02:...|\n",
            "+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_session_timestamp.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwiwGeXRDNk2",
        "outputId": "a85d67d4-7875-4896-a646-64d659296043"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+--------+------+\n",
            "|           sessionid|refunded|amount|\n",
            "+--------------------+--------+------+\n",
            "|00029153d12ae1c9a...|   false|    85|\n",
            "|008909bd27b680698...|   false|    13|\n",
            "|0107acb41ef20db22...|   false|    16|\n",
            "|018544a2c48077d2c...|   false|    39|\n",
            "|020c38173caff0203...|   false|    61|\n",
            "+--------------------+--------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_session_transaction.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2tg1Myi8Q5I"
      },
      "source": [
        "## 총 매출이 가장 많은 사용자 10명 찾기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "GdiSxs1030G0"
      },
      "outputs": [],
      "source": [
        "top_rev_user_df = spark.sql(\"\"\"\n",
        "    SELECT userid,\n",
        "        SUM(str.amount) revenue\n",
        "    FROM user_session_channel usc\n",
        "    JOIN session_transaction str ON usc.sessionid = str.sessionid\n",
        "    GROUP BY 1\n",
        "    ORDER BY 2 DESC\n",
        "    LIMIT 10\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whIte26D63hG",
        "outputId": "92bd281a-7fba-4fac-ca89-7f62697cb480"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+-------+\n",
            "|userid|revenue|\n",
            "+------+-------+\n",
            "|   989|    743|\n",
            "|   772|    556|\n",
            "|  1615|    506|\n",
            "|   654|    488|\n",
            "|  1651|    463|\n",
            "|   973|    438|\n",
            "|   262|    422|\n",
            "|  1099|    421|\n",
            "|  2682|    414|\n",
            "|   891|    412|\n",
            "+------+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "top_rev_user_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "bVSpjPBq83LW"
      },
      "outputs": [],
      "source": [
        "top_rev_user_df2 = spark.sql(\"\"\"\n",
        "    SELECT userid,\n",
        "        SUM(str.amount) revenue,\n",
        "        SUM(CASE WHEN str.refunded = False THEN str.amount END) net_revenue\n",
        "    FROM user_session_channel usc\n",
        "    JOIN session_transaction str ON usc.sessionid = str.sessionid\n",
        "    GROUP BY 1\n",
        "    ORDER BY 2 DESC\n",
        "    LIMIT 10\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCjgcU1-9AC_",
        "outputId": "842c765e-beaf-439f-db26-442f281cb0e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+-------+-----------+\n",
            "|userid|revenue|net_revenue|\n",
            "+------+-------+-----------+\n",
            "|   989|    743|        743|\n",
            "|   772|    556|        556|\n",
            "|  1615|    506|        506|\n",
            "|   654|    488|        488|\n",
            "|  1651|    463|        463|\n",
            "|   973|    438|        438|\n",
            "|   262|    422|        422|\n",
            "|  1099|    421|        343|\n",
            "|  2682|    414|        414|\n",
            "|   891|    412|        412|\n",
            "+------+-------+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "top_rev_user_df2.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "W7JRcaAnbCHu"
      },
      "outputs": [],
      "source": [
        "top_rev_user_df3 = spark.sql(\"\"\"\n",
        "SELECT\n",
        "  userid,\n",
        "  SUM(amount) total_amount,\n",
        " \tRANK() OVER (ORDER BY SUM(amount) DESC) rank\n",
        "FROM session_transaction st\n",
        "JOIN user_session_channel usc ON st.sessionid = usc.sessionid\n",
        "GROUP\tBY userid\n",
        "ORDER BY rank\n",
        "LIMIT 10\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C50aAfvibpao",
        "outputId": "323ea89f-e056-4f92-acff-40e683bb2053"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+------------+----+\n",
            "|userid|total_amount|rank|\n",
            "+------+------------+----+\n",
            "|   989|         743|   1|\n",
            "|   772|         556|   2|\n",
            "|  1615|         506|   3|\n",
            "|   654|         488|   4|\n",
            "|  1651|         463|   5|\n",
            "|   973|         438|   6|\n",
            "|   262|         422|   7|\n",
            "|  1099|         421|   8|\n",
            "|  2682|         414|   9|\n",
            "|   891|         412|  10|\n",
            "+------+------------+----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "top_rev_user_df3.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
